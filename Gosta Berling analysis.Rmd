---
title: |
    | Sad songs & pretty charts: 
    | *a Gosta Berling music data visualization* 
author: "greg dubrow"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "images/",
  out.width = "100%")
```

## Using the Spoitfy API and spotifyr package to visualize some music I've made

For my first post, I thought I'd focus on music analytics, given that music and data science/analysis are two things I've probably spent most of my waking hours on for a number of years now. 

Over the years I've made a lot of music in a number of different projects. For most of my time living in the Bay Area I've played with some friends in a band called [Gosta Berling](https://gostaberling.bandcamp.com/). We've released two EPs and a full album *(click on the album covers to give listen)*

[![Winterland](images/gb_winterland_sm.jpg)](https://gostaberling.bandcamp.com/album/winterland) [![Winterland](images/gb_travel_sm.jpg)](https://gostaberling.bandcamp.com/album/travel) [![Winterland](images/gb_sweetheart_sm.jpg)](https://gostaberling.bandcamp.com/album/everybodys-sweetheart)




Our sound could be called melancholy mood-pop. We like melody, but we were raised on post-punk and that minor key vibe is definitely present. So since the Spotify API has musical features including danceability, energy, and valence (what they call 'happiness'), I thought I'd try and learn Charlie Thompson's [spotifyr](https://github.com/charlie86/spotifyr) package and see how we score. spotifyr has a bunch of functions designed to make it easier to navigate Spotify's JSON data structure. 

So first thing, let's load the packages we'll be using:

```{r pkg load, message=FALSE, ECHO = FALSE}
library(tidyverse)
library(tidylog)
library(httr)
library(stringr)
library(lubridate)
library(ggrepel)
library(spotifyr)
library(janitor)
library(GGally)
library(PerformanceAnalytics)
library(corrr)

```

The spotifyr package is available from CRAN or from the dev version:

```{r  eval = FALSE}
# install.packages("spotifyr")
# devtools::install_github('charlie86/spotifyr', force = TRUE)
```

To get access the Spotify data, you need a developer key. Charlie's explained how to do it on the package page, so I won't repeat that here. To set up the keys in your .Renviron, run

```{r  eval = FALSE}
usethis::edit_r_environ()
```

and add:

```{r set up keys, eval = FALSE}
SPOTIFY_CLIENT_ID = 'xxxxxxxxxxxxxxxxxxxxx'
SPOTIFY_CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx'

# or do
Sys.setenv(SPOTIFY_CLIENT_ID = 'xxxxxxxxxxxxxxxxxxxxx')
Sys.setenv(SPOTIFY_CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx')
```

This call sets your access token for the data session
```{r ECHO = FALSE}
access_token <- get_spotify_access_token()
```

If you run into redirect issues, see [this stackoverflow thread (https://stackoverflow.com/questions/32956443/invalid-redirect-uri-on-spotify-auth), specifically [this comment](https://stackoverflow.com/a/51967789/102268480)

First thing is to search the artist data for audio features. I'm pulling in everything into a dataframe
```{r eval = FALSE}
# gets full range of information for tracks from artist
gosta_audio1 <- get_artist_audio_features(artist = 'Gosta Berling')
glimpse(gosta_audio1)
```

For some reason the search was only returning data for last album Winterland, so I need to get audio info on a song-by-song basis. At first just looked up the EP data, but the dataframes came back with results in a different format than the Winterland data, so I decided to just get everything the same way. 

First, I looked up the album IDs on Spotify:

- Gosta Berling artist id = 4Vb2yqJJthJTAZxKz4Aryn
- Travel album id = 0vBs7ZtBj3ROrRyac3M47q
- Everybody's Sweetheart album id = 0dJBaJ3VFxOtdG5L9yzALJ
- Winterland album id = 6CMekiY6lCIuBZpzFDInpf

The code here gets a dataframe for each record. I also needed to add album title.
Next steps were to merge the album dataframes together, extract the song IDs and pass them to the get_track_features() function as a list.
```{r ECHO = FALSE}
# get album tracks, add album name could merge on other df, easier to quick fix this way
travel <- get_album_tracks(id = "0vBs7ZtBj3ROrRyac3M47q")
travel$album <- "Travel"
sweetheart <- get_album_tracks(id = "0dJBaJ3VFxOtdG5L9yzALJ")
sweetheart$album <- "Everybody's Sweetheart"
winterland  <- get_album_tracks(id = "6CMekiY6lCIuBZpzFDInpf")
winterland$album <- "Winterland"

# merge album files, output track ids to use for audio features
gbtracks <- data.table::rbindlist(list(sweetheart, travel, winterland))
gbtrackids <- dput(as.character(gbtracks$id)) # copy result from console

gosta_audio2 <- 
  get_track_audio_features(c("2SotrXjkvjTZf05XSMKGyp", "07cTJ65GZ4Lvr6b1CtgPll",
                                       "4ooz79IN3la97See8IMNRL","7pgCh68iFO0LNUNKWTFFIP", 
                                       "4ZCesDRgGWKEXwq8iKw5FB", "4ZdH5B3tijHjWiwyOErgtf", 
                                       "5GWKeBYgOsv3PKutDIQoet", "0XXWRsY6URe2Vx7Bxs6k06",
                                       "0t3AGVXHyF3dEYuhvAYuNz", "4ObsuwrVLKUq5aF8whrFqk", 
                                       "0PnjWfIPwsqBtllMILjzxB", "7uQtlGsKxXOzsSapKTZRFU", 
                                       "3kQuG44stzA3pQf7g61Ipt", "0YH9wkimhRhCmstNZyxPgO",
                                       "7rEbjyNO0dTEK6x8HkLqAz", "4VgEAtVQtkwIHzKMOROk6X",
                                       "5R9M4s6QZljNPVVzxoy98h", "1FNtHQ0juoKg2yCf9u4VSg", 
                                       "5NWmfmupE7FEJ9O1e9vizu"),
                                     authorization = get_spotify_access_token())
glimpse(gosta_audio2)
```

Result is a dataframe with most of what I want...just a few tweaks needed.
First, since they weren't pulled from the get_track_audio_features() call, I got the track id, name, and album track number merge from the gbtracks dataframe. Also, because the song key returned as only the numeric value, I created the letter name and mode (major or minor), and ordered the columns.

```{r ECHO = FALSE}
# get track number and name, merge from gbtracks - 
# need b/b not returned from get_track_audio_features()
gbtrack2 <- gbtracks %>%
  select(id, name, album, track_number) %>%
  rename(track_name = name)

# merge to complete df. add names for key and mode
gosta_audio <- left_join(gosta_audio2, gbtrack2) %>%
  mutate(key_name = case_when(key == 0 ~ "C", key == 2 ~ "D", key == 4 ~ "E", 
                              key == 5 ~ "F", key == 7 ~ "G", 
                              key == 9 ~ "A", key == 11 ~ "B")) %>%
  mutate(mode_name = case_when(mode == 0 ~ "Minor", mode == 1 ~ "Major")) %>%
  mutate(key_mode = paste(key_name, mode_name, sep = " ")) %>%
  rename(track_id = id) %>%
  select(album, track_name, track_number, key_mode, time_signature, duration_ms, 
         danceability, energy, loudness, tempo, valence, 
         acousticness, instrumentalness, liveness, speechiness,
         key_name, mode_name, key, mode)
  
glimpse(gosta_audio)
```

The result is a nice tidy dataframe, ready for some analysis.

[Spotify's developer pages](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) have good explanations of the data. Some notes from spotify here about elements: 

- Most of the aduio features are 0-1, 1 being highest. e.g. higher speechiness = higher ratio of words::music. Valence is "happiness", where higher = happier.
- Loundess in dB, tempo is BPM

First I wanted to look at basic correlations for the values. There are a number of ways to run and visualize correlations in r...a few examples follow. First thing I needed to do was a subset of the gosta_audio df for easier calls with the various correlation packages.
```{r ECHO = FALSE}
gbcorr <- gosta_audio[, c(6:15)]
```

Let's try correlations in base r. You get the coefficients in the console or you can output to a dataframe to hard-code the visualization.
```{r ECHO = FALSE}
cor(gbcorr)
gbcorrs1 <- as.data.frame(cor(gbcorr))
```

Or you could let some packages do the viz work for you.
First, the ggally package.
```{r ECHO = FALSE}
ggcorr(gbcorr, label = TRUE)
```

We see here some strong postive associations with energy & loundess returning a .9 coefficient, and liveness & speechiness and energy & valence each returing at .7 coefficient. The energy & acousticness and loudness & acousticness combinations each return a -.7 coefficient, showing a negative relationship between those music features. 

With the corrr package I tried a couple of approaches. First a basic matrix that prints to the console, and doesn't look much different than base r.
```{r ECHO = FALSE}
gbcorr %>%
  correlate(use = "pairwise.complete.obs", method = "spearman")
```

Next, I used their rplot call and then rendered a network graph using the network_plot() call.
```{r ECHO = FALSE}
gbcorrs2 <- correlate(gbcorr)
rplot(gbcorrs2)
   # network graph
correlate(gbcorr) %>% 
  network_plot(min_cor=0.5)
```

And finally the  performance analytics package, which was the first of the packages to include significance levels in the default output.
```{r ECHO = FALSE}
#chart.Correlation(gbcorr, histogram=TRUE, pch="+")
chart.Correlation(gbcorr, histogram = FALSE, method = c("pearson", "kendall", "spearman"))

```

Given the correlations, I was interested in exploring the relationships a bit more. So I ran a few scatterplots, with song titles as data labels, and dots colored by album name (using primary color from the cover) to see also if any of the albums clustered at all along either axis. The ggrepel package is used to move the labels off of the dots

First, up, energy and valence, or happiness. Spotify uses the term valence to signify happiness, or "musical positiveness". For energy, as they put it "Typically, energetic tracks feel fast, loud, and noisy." Again, 
[see the API documentation](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) for definitions.
```{r fig.width=7.5, fig.height=4.0, dpi = 300, ECHO = FALSE}
gosta_audio %>%
  ggplot(aes(energy, valence, color = album)) +
  geom_point() +
  geom_smooth(aes(color = NULL)) +
  geom_text_repel(aes(label = track_name), size = 3) +
  scale_color_manual(values = c("#707070", "brown", "dark blue")) +
  ylim(0, 1) +
  xlim(0, 1) +
  theme_minimal() +
  labs(x = "energy", y = "valence (happiness)") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

There is a bit of a relationship between the Energy score and Valence - so our more energetic songs are our happiest songs. Another interesting way to explore this would be to do some sentiment analysis on the lyics and see if there's a relationship between energy, valence and using words considered to be more positive in nature.

Next I wondered if there's a relationship between song tempo (beats per minute) & happiness. Our average BPM is 131, which isn't too far the the mid-range of songs on Spotify. The histogram below comes from the [Spotify API page](https://developer.spotify.com/assets/audio/tempo.png) ![](https://developer.spotify.com/assets/audio/tempo.png)

So let's see the code and resulting scatterplot...
```{r fig.width=7.5, fig.height=4.0, dpi = 300, ECHO = FALSE}
gosta_audio %>%
  ggplot(aes(tempo, valence, color = album)) +
  geom_point() +
  geom_smooth(aes(color = NULL)) +
  geom_text_repel(aes(label = track_name), size = 3) +
  scale_color_manual(values = c("#707070", "brown", "dark blue")) + 
  ylim(0, 1) +
  theme_minimal() +
  labs(x = "tempo (bpm)", y = "valence (happiness)") +
  theme(legend.position = "bottom", legend.title = element_blank())
```
It's not until we get to about the 130 BPM range is it that our songs start to get to about a .5 valence (happiness) score, and from there the relationship between tempo & happiness really kicks in.


Finally, tempo and energy
```{r fig.width=7.5, fig.height=4.0, dpi = 300, ECHO = FALSE}
gosta_audio %>%
  ggplot(aes(tempo, energy, color = album)) +
  geom_point() +
  geom_smooth(aes(color = NULL)) +
  geom_text_repel(aes(label = track_name), size = 3) +
  scale_color_manual(values = c("#707070", "brown", "dark blue")) +
  ylim(0, 1) +
  theme_minimal() +
  labs(x = "tempo (bpm)", y = "energy") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

So yes, most of our songs are in the bottom half of the happy scale. And there does seem to be a bit of a relationship between tempo, energy and happiness and of course a relationship between tempo and energy. Going forward, I'd love to explore our song lyrics via text analysis, especially sentiment analysis to see if the songs Spotify classified as our most sad (low valence) had lyrics that were less positive. 

So if you like slightly melancholy mood-pop that's in the 130 +/- BPM range, I think you'll like us. 